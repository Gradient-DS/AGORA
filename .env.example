# ============================================================
# Required
# ============================================================
OPENAI_API_KEY=sk-...

# ============================================================
# Backend Selection
# ============================================================
# Default backend for API gateway (langgraph, openai, mock)
DEFAULT_BACKEND=langgraph

# Frontend backend selection (langgraph, openai, mock)
VITE_BACKEND=langgraph

# ============================================================
# Optional: LangGraph LLM Configuration
# ============================================================
# Use alternative OpenAI-compatible provider
# LANGGRAPH_OPENAI_BASE_URL=https://api.together.ai/v1
# LANGGRAPH_OPENAI_MODEL=meta-llama/Llama-3.3-70B-Instruct-Turbo

# ============================================================
# Optional: Faster Model for Spoken Text Generation
# ============================================================
# Use a different (faster) model for spoken text generation
# If not set, uses the same model as written text
# LANGGRAPH_SPOKEN_MODEL=openai/gpt-oss-120b
# LANGGRAPH_SPOKEN_BASE_URL=https://api.fireworks.ai/inference/v1
# LANGGRAPH_SPOKEN_API_KEY=your_fireworks_api_key

# ============================================================
# Optional: Authentication
# ============================================================
# Comma-separated API keys (empty = no auth required)
# API_KEYS=key1,key2,key3
# REQUIRE_AUTH=true

# ============================================================
# Optional: Frontend (non-sensitive, baked into build)
# ============================================================
VITE_APP_NAME=AGORA HAI

# Note: ElevenLabs API key should NOT be in Docker builds
# For voice features, either:
# 1. Proxy ElevenLabs calls through your backend (recommended)
# 2. Use runtime config injection
# 3. Only use in local dev with HAI/.env file

# ============================================================
# Legacy: Local Development (without docker-compose)
# ============================================================
# server-openai
# OPENAI_AGENTS_OPENAI_API_KEY=your_openai_api_key
# OPENAI_AGENTS_OPENAI_MODEL=gpt-4o
# OPENAI_AGENTS_MCP_SERVERS=regulation=http://localhost:5002,reporting=http://localhost:5003,history=http://localhost:5005

# server-langgraph
# LANGGRAPH_OPENAI_API_KEY=your_api_key
# LANGGRAPH_OPENAI_BASE_URL=https://api.openai.com/v1
# LANGGRAPH_OPENAI_MODEL=gpt-4o
# LANGGRAPH_MCP_SERVERS=regulation=http://localhost:5002,reporting=http://localhost:5003,history=http://localhost:5005

# MCP Servers
# MCP_WEAVIATE_URL=http://localhost:8080
# MCP_OPENAI_API_KEY=your_openai_api_key
# MCP_EMBEDDING_PROVIDER=openai

# ============================================================
# Document Ingestion (docker compose run --rm document-ingestion)
# ============================================================
# Embedding provider: openai (default, uses text-embedding-3-small) or local (nomic)
MCP_EMBEDDING_PROVIDER=openai

# ============================================================
# Optional: Email Notifications (Microsoft Graph API)
# ============================================================
# Required for sending inspection reports via email
# MCP_GRAPH_TENANT_ID=your_azure_tenant_id
# MCP_GRAPH_CLIENT_ID=your_azure_app_client_id
# MCP_GRAPH_CLIENT_SECRET=your_azure_app_client_secret
# MCP_GRAPH_MAIL_SENDER_ADDRESS=noreply@yourdomain.com
# MCP_GRAPH_MAIL_SENDER_DISPLAY=AGORA